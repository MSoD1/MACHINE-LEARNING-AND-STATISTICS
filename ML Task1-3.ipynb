{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Tasks: Machine Learning and Statistics\n***Machine Learning and Statistics - Tasks 2023***\n\n **Introduction**<br>\n    This notebook forms a part of the assignment for the module Machine Lerning and Statistics.<br>\n    The notebook consist of discussion and solutions to five tasks:<br>\n    \n> **Tasks**: <br> \n        <p style='text-align: justify;'> 1. Square roots are difficult to calculate. In Python, you typically use the power operator (a double asterisk) or a package such as math. In this task, you should write a function $\\sqrt(x)$ to approximate the square root of a floating point number x without using the power operator or a package.<br>\nRather, you should use the Newtonâ€™s method. Start with an initial guess for the square root called $z_{0}$. You then repeatedly improve it using the following formula, until the difference between some previous guess $z_{i}$ and the next  $z_{i+1}$ is less than some threshold, say 0.01.<br> </p> <br> <p style='text-align: center;'> $z_{i+1} = z_{i} - \\frac{z_{i} \\times z_{i}-x}{2z_{i}}$ <br> </p>\n    <p style='text-align: justify;'><br>2. Consider the below contingency table based on a survey asking respondents whether they prefer coffee or tea and whether they prefer plain or chocolate biscuits. Use scipy.stats to perform a chi-squared test to see whether there is any evidence of an association between drink preference and biscuit preference in this instance.</p> <br> <p style='text-align: center;'><table><thead><td></td><td>*Biscuit*</td></thead> <thead><tr><th></th><th>Chocolate</th><th>Plain</th></tr></thead><tbody><tr><td rowspan=\"2\">*Drink*</td><th>Coffee</th><td>43</td><td>57</td></tr><tr><th>Tea</th><td>56</td><td>45</td></tr></tbody></table><br> </p> \n    <p style='text-align: justify;'>3. Perform a t-test on the famous penguins data set to investigate whether there is evidence of a significant difference in the body mass of male and female gentoo penguins.<br> </p> \n    <p style='text-align: justify;'>4. Using the famous iris data set,suggest whether the setosa class is easily separable from the other two classes. Provide evidence for your answer. <br> </p> \n    <p style='text-align: justify;'>5. Perform Principal Component Analysis on the iris data set,reducing the number of dimensions to two. Explain the purposeof the analysis and your results. <br> </p> \n    ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " **Task 1**<br>\n ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def newton_method(number, number_iters = 500):\n    a = float(number) # number to get square root of\n    for i in range(number_iters): # iteration number\n        number = 0.5 * (number + a / number) # update\n\t  # x_(n+1) = 0.5 * (x_n +a / x_n)\n    return number\n\nprint(newton_method(20))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": "4.47213595499958\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": " **Task 2**<br>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<p style='text-align: justify;'> A chi-square test of independence is used to determine whether or not there is a significant association between two categorical variables. The following hypotheses will be tested: <br> </p> <p style='text-align: center;'> $H_{0}$ There is no relationship between drink preference and biscuit preference.<br> </p> <p style='text-align: center;'> $H_{1}$ There is relationship between drink preference and biscuit preference.<br> </p> ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# import required libraries\nimport numpy as np\n\nfrom scipy.stats import chi2_contingency\ndata = np.array([[43,57], [56,45]])\n\nchi2, p, dof, expected = chi2_contingency(data)\n\nprint(f\"Chi-squared test: {chi2:.2f}\")\nprint(f\"P-value: {p:.5f}\")\nprint(f\"Degrees of freedom: {dof}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[43 57]\n [56 45]]\nChi-squared test: 2.64\nP-value: 0.10447\nDegrees of freedom: 1\nExpected frequencies:\n [[49.25373134 50.74626866]\n [49.74626866 51.25373134]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<p style='text-align: justify;'> With 1 degrees of freedom and alpha = 0.05, using statistical tables to find the critical value of 3.84146. Since chi -squared is not greater then the critical value, we fail to reject the null hypothesis. The p-value for the test comes out to be strictly greater than the alpha value, we will accept our  $H_{0}$. Concluding there is no relationship between drink preference and biscuit preference.<br> </p> ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " **Task 3**<br>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport scipy.stats as sps\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind\n\ndf = pd.read_csv(\"C://Users/odonovanm/Desktop/programming/MachineLearning/penguins.csv\")\n#print(df.sample(10))\n#df.info()\n#print(df.isnull().sum())\nmean_bill_length = round(df['bill_length_mm'].mean(),1)\nmean_bill_depth = round(df['bill_depth_mm'].mean(),1)\nmean_flipper_length = round(df['flipper_length_mm'].mean(),1)\nmean_body_mass = round(df['body_mass_g'].mean(),1)\n\n#Remove any null values that might skew the data\ndf['bill_length_mm'].replace(np.nan , mean_bill_length , inplace=True)\ndf['bill_depth_mm'].replace(np.nan , mean_bill_depth , inplace=True)\ndf['flipper_length_mm'].replace(np.nan , mean_flipper_length , inplace=True)\ndf['body_mass_g'].replace(np.nan , mean_body_mass , inplace=True)\n\n#print(df.isnull().sum())\ndf.dropna(subset=['sex'] , axis = 0 , inplace = True)\n\n#print(df.isnull().sum())\n#print(\"observation : \",len(df))\nMale_Penguins = df.loc[df[\"sex\"] == \"MALE\", \"body_mass_g\"]\nFemale_Penguins = df.loc[df[\"sex\"] == \"FEMALE\", \"body_mass_g\"]\nprint(ttest_ind(Male_Penguins, Female_Penguins))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ttest_ind\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC://Users/odonovanm/Desktop/programming/MachineLearning/penguins.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<p style='text-align: justify;'> The p-value < 0.05, means the hypothesis stating the mean of both groups is not significantly different is false and hence rejected.</br>\nHence, you can conclude that the average body mass of male and female penguins significantly varies.</p>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}